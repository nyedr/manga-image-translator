services:
  manga_image_translator:
    build:
      context: ../..
      dockerfile: Dockerfile
    container_name: manga_image_translator_gpu

    # run the server
    entrypoint: python
    command: server/main.py --verbose --start-instance --host=0.0.0.0 --port=5003 --use-gpu --font-path /app/fonts/NotoSansMonoCJK-VF.ttf.ttc

    # enable GPU
    gpus: all
    ipc: host

    # mount your code & results
    volumes:
      - ../../result:/app/result
      - ../../server:/app/server
      - ../../manga_translator:/app/manga_translator

    ports:
      - "5003:5003"

    environment:
      # Ollama / “custom openai” settings
      CUSTOM_OPENAI_API_KEY: "ollama"
      CUSTOM_OPENAI_API_BASE: "http://host.docker.internal:11434/v1"
      CUSTOM_OPENAI_MODEL: "gemma3:12b"
      # you can leave the rest blank or fill in any others you need:
      OPENAI_API_KEY: ""
      OPENAI_API_BASE: ""
      OPENAI_MODEL: ""
      OPENAI_HTTP_PROXY: ""
      # …etc…
