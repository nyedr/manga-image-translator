version: "3.8"

services:
  manga_image_translator:
    image: zyddnys/manga-image-translator:main
    container_name: manga_image_translator_gpu

    # run the server
    entrypoint: python
    command: server/main.py --verbose --start-instance --host=0.0.0.0 --port=5003 --use-gpu

    # enable GPU
    gpus: all
    ipc: host

    # mount your code & results
    volumes:
      - ../../result:/app/result
      - ../../server:/app/server

    ports:
      - "5003:5003"

    environment:
      # Ollama / “custom openai” settings
      CUSTOM_OPENAI_API_KEY: "ollama"
      CUSTOM_OPENAI_API_BASE: "http://host.docker.internal:11434/v1"
      CUSTOM_OPENAI_MODEL: "qwen2.5vl:7b"
      # you can leave the rest blank or fill in any others you need:
      OPENAI_API_KEY: ""
      OPENAI_API_BASE: ""
      OPENAI_MODEL: ""
      OPENAI_HTTP_PROXY: ""
      # …etc…
